import pandas as pd
import os
from datetime import datetime
import re

class WireBondingAnalyzer:
    def __init__(self):
        self.nobump_df = None
        self.wb_data = None
        self.efficiency_df = None
        self.raw_data = None
    
    def normalize_model_name(self, model_name):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô"""
        if not isinstance(model_name, str):
            model_name = str(model_name)
        model_name = model_name.strip().upper()
        if 'WB3100' in model_name:
            return 'WB3100'
        elif 'WB3200' in model_name:
            return 'WB3200'
        elif 'WB3300' in model_name:
            return 'WB3300'
        else:
            return model_name
        
    def normalize_optn_code(self, optn_name):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏£‡∏´‡∏±‡∏™ Option Code ‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô"""
        if not isinstance(optn_name, str):
            optn_name = str(optn_name)

        optn_name = optn_name.strip().upper()

        mapping = {
         "L/B-ROV-CU": "W/B-ROV-CU",
         "L/B-ROVING": "W/B-ROV",
        }

        for key, value in mapping.items():
            if optn_name in key:
                return value
            
        for key, value in mapping.items():
            if key in optn_name:  # optn_name = "W/B-ROV-CU"
                return value

        return optn_name
        
    def clean_model_names(self, df):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á"""
        df = df.copy()
        if 'machine_model' in df.columns:
            df['machine_model'] = df['machine_model'].apply(self.normalize_model_name)
        if 'optn_code' in df.columns:
            df['optn_code'] = df['optn_code'].apply(self.normalize_optn_code)
        return df
    
    def find_wire_data_file(self, directory_path=None):
        """‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Wire Data: ‡πÉ‡∏ä‡πâ Part bom pkg.xlsx ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_MAP ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå"""
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            src_dir = os.path.dirname(current_dir)
            wire_data_path = os.path.join(src_dir, "data_MAP", "Part bom pkg.xlsx")
            if os.path.exists(wire_data_path):
                return wire_data_path
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Part bom pkg.xlsx ‡πÉ‡∏ô {os.path.join(src_dir, 'data_MAP')}")
            return None
        except Exception as e:
            print(f"‚ùå find_wire_data_file error: {e}")
            return None
    
    def load_data(self, uph_path, wire_data_path=None):
        """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
        try:
            # ‡∏´‡∏≤ wire_data_path ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏
            if wire_data_path is None:
                wire_data_path = self.find_wire_data_file()
                if wire_data_path is None:
                    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Part bom pkg")
                    return False

            # ‡πÇ‡∏´‡∏•‡∏î Wire Data
            print(f"üìä Loading Wire data from: {os.path.basename(wire_data_path)}")
            self.nobump_df = pd.read_excel(wire_data_path)
            self.nobump_df.columns = (
                self.nobump_df.columns
                .str.strip()
                .str.lower()
                .str.replace(' ', '_')
                .str.replace('-', '_')
            )
            # Map ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Wire Data
            col_map = {}
            for col in self.nobump_df.columns:
                norm = col.replace('_', '').replace(' ', '').lower()
                if norm in ['bomno', 'bom', 'bom_no']:
                    col_map[col] = 'bom_no'
                elif norm in ['#ofwire1']:
                    col_map[col] = 'number_required'
                elif norm in ['#ofbump1']:
                    col_map[col] = 'no_bump'
                elif norm in ['wire1']:
                    col_map[col] = 'item_no'
                elif norm in ['#ofwire2']:
                    col_map[col] = 'number_required_2'
                elif norm in ['bomrev', 'bom_rev']:
                    col_map[col] = 'bom_rev'
                elif norm in ['packagecode', 'package_code', 'pkgcode', 'pkg_code']:
                    col_map[col] = 'package_code'
                elif norm in ['productnumber', 'product_number', 'productno', 'product_no']:
                    col_map[col] = 'product_number'
            self.nobump_df.rename(columns=col_map, inplace=True)
            if 'bom_no' in self.nobump_df.columns:
                self.nobump_df['bom_no'] = self.nobump_df['bom_no'].astype(str).str.strip().str.upper()
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏µ‡∏¢‡πå‡∏≠‡∏∑‡πà‡∏ô ‡πÜ
            for k in ['bom_rev', 'package_code', 'product_number']:
                if k in self.nobump_df.columns:
                    self.nobump_df[k] = self.nobump_df[k].astype(str).str.strip().str.upper()
            print(f"‚úÖ Wire data loaded: {len(self.nobump_df)} rows")

            # ‡πÇ‡∏´‡∏•‡∏î UPH Data
            print(f"üìä Loading UPH data from: {os.path.basename(uph_path)}")
            ext = os.path.splitext(uph_path)[-1].lower()
            if ext == '.csv':
                self.raw_data = pd.read_csv(uph_path, encoding='utf-8-sig')
            elif ext in ['.xlsx', '.xls']:
                self.raw_data = pd.read_excel(uph_path)
            elif ext == '.json':
                self.raw_data = pd.read_json(uph_path)
            else:
                print(f"‚ùå Unsupported file type: {ext}")
                return False

            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå UPH
            self.raw_data.columns = (
                self.raw_data.columns
                .str.strip()
                .str.lower()
                .str.replace(' ', '_')
                .str.replace('-', '_')
            )

            # Map ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå UPH
            col_map = {}
            for col in self.raw_data.columns:
                norm = col.replace('_', '').lower()
                if norm in ['machinemodel', 'model']:
                    col_map[col] = 'machine_model'
                elif norm in ['bomno', 'bom', 'bom_no']:
                    col_map[col] = 'bom_no'
                elif norm == 'uph':
                    col_map[col] = 'uph'
                elif norm in ['optncode', 'optn_code']:
                    col_map[col] = 'optn_code'
                elif norm == 'operation':
                    col_map[col] = 'operation'
                elif norm in ['device']:
                    col_map[col] = 'device'
                elif norm in ['packagecode', 'package_code']:   # FIX: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÅ‡∏ö‡∏ö
                    col_map[col] = 'package_code'
                elif norm in ['bomrev', 'bom_rev']:              # FIX: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÅ‡∏ö‡∏ö
                    col_map[col] = 'bom_rev'
            self.raw_data.rename(columns=col_map, inplace=True)
            print(f"‚úÖ UPH data loaded: {len(self.raw_data)} rows")

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            required_columns = ['uph', 'machine_model', 'bom_no']
            missing_columns = [col for col in required_columns if col not in self.raw_data.columns]
            if missing_columns:
                print(f"‚ùå Missing required columns: {missing_columns}")
                print(f"üìã Available columns: {list(self.raw_data.columns)}")
                return False

            print("‚úÖ Data loaded successfully!")
            return True

        except Exception as e:
            print(f"‚ùå Error loading data: {e}")
            return False
    
    # ‡∏ï‡∏±‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå Map ‡∏î‡πâ‡∏ß‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏µ‡∏¢‡πå
    def _filter_map_rows(self, bom_no, bom_rev=None, package_code=None, product_number=None):
        df = self.nobump_df.copy()
        if df is None or df.empty:
            return df.iloc[0:0]
        def norm(v): 
            return str(v).strip().upper()
        mask = (df['bom_no'].astype(str).str.strip().str.upper() == norm(bom_no))
        if bom_rev is not None and 'bom_rev' in df.columns:
            mask &= (df['bom_rev'].astype(str).str.strip().str.upper() == norm(bom_rev))
        if package_code is not None and 'package_code' in df.columns:
            mask &= (df['package_code'].astype(str).str.strip().str.upper() == norm(package_code))
        # Product Number ‡πÉ‡∏ô Map
        if product_number is not None:
            if 'product_number' in df.columns:
                mask &= (df['product_number'].astype(str).str.strip().str.upper() == norm(product_number))
        return df[mask]

    # ‡∏ï‡∏±‡∏ß‡∏ä‡πà‡∏ß‡∏¢: wire2 "‡∏°‡∏µ‡∏Ñ‡πà‡∏≤" ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ > 0 (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° NaN/‡∏ß‡πà‡∏≤‡∏á/‡∏®‡∏π‡∏ô‡∏¢‡πå)
    def _wire2_has_value(self, rows):
        try:
            if rows.empty or 'number_required_2' not in rows.columns:
                return False
            v = rows['number_required_2'].iloc[0]
            # ‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠ NaN ‚Üí ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤
            if v is None or (isinstance(v, float) and pd.isna(v)):
                return False
            s = str(v).strip()
            if s == '' or s.lower() == 'nan':
                return False 
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡∏ñ‡πâ‡∏≤ > 0 ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡πà‡∏≤
            n = pd.to_numeric(s, errors='coerce')
            return pd.notna(n) and n > 0
        except Exception:
            return False

    def calculate_wire_per_unit(self, bom_no, optn_code=None, bom_rev=None, package_code=None, product_number=None):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Map ‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ Bom Rev, Package Code, Product Number
           ‡∏ñ‡πâ‡∏≤ wire2 ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ ‚Üí ‡πÑ‡∏°‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì (‡∏Ñ‡∏∑‡∏ô None)"""
        try:
            rows = self._filter_map_rows(bom_no, bom_rev=bom_rev, package_code=package_code, product_number=product_number)
            if rows.empty:
                return None
            # ‡∏ñ‡πâ‡∏≤ wire2 ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ ‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
            if self._wire2_has_value(rows):
                return None

            no_bump = rows['no_bump'].iloc[0] if 'no_bump' in rows.columns else None
            num_required = rows['number_required'].iloc[0] if 'number_required' in rows.columns else None
            if pd.isna(no_bump) or pd.isna(num_required):
                return None
            no_bump = float(no_bump); num_required = float(num_required)
            wire_per_unit = (no_bump / 2.0) + num_required
            return wire_per_unit if wire_per_unit > 0 else None
        except Exception as e:
            print(f"‚ùå Error calculating wire per unit for BOM {bom_no} : {e}")
            return None

    def get_wire_info_for_bom_optn(self, bom_no, optn_code, bom_rev=None, package_code=None, product_number=None):
        """‡∏î‡∏∂‡∏á ITEM_NO, NO_BUMP, NUMBER_REQUIRED ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Map ‡∏ï‡∏≤‡∏° BOM + Bom Rev + Package Code + Product Number
           ‡∏ñ‡πâ‡∏≤ wire2 ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ ‚Üí ‡∏Ñ‡∏∑‡∏ô (item_no, None, None)"""
        try:
            rows = self._filter_map_rows(bom_no, bom_rev=bom_rev, package_code=package_code, product_number=product_number)
            if rows.empty:
                return None, None, None

            item_no = rows['item_no'].iloc[0] if 'item_no' in rows.columns else None

            # ‡∏ñ‡πâ‡∏≤ wire2 ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ ‡πÉ‡∏´‡πâ blank no_bump/number_required ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô
            if self._wire2_has_value(rows):
                return item_no, None, None

            no_bump = rows['no_bump'].iloc[0] if 'no_bump' in rows.columns else None
            number_required = rows['number_required'].iloc[0] if 'number_required' in rows.columns else None
            return item_no, no_bump, number_required
        except Exception as e:
            print(f"‚ùå Error getting wire info for BOM {bom_no}: {e}")
            return None, None, None

    def remove_outliers(self, df):
        """‡∏•‡∏ö outliers ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏∏‡∏•"""
        try:
            if df.empty:
                return df, {}
            df = self.clean_model_names(df)
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            required_cols = ['uph', 'machine_model', 'bom_no']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise KeyError(f"Missing required columns: {missing_cols}")

            # ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏µ‡∏¢‡πå‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö calculate_efficiency
            group_keys = ['bom_no', 'machine_model', 'optn_code', 'bom_rev', 'device', 'package_code']
            group_keys = [k for k in group_keys if k in df.columns]  # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏°‡∏µ
            grouped = df.groupby(group_keys, dropna=False)

            cleaned_data = []
            outlier_info = {}

            for group_key, group_data in grouped:
                # group_key ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô str ‡∏´‡∏£‡∏∑‡∏≠ tuple ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô key
                if not isinstance(group_key, tuple):
                    group_key = (group_key,)
                group_data = group_data.copy()
                original_count = len(group_data)

                # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 15 ‡∏à‡∏∏‡∏î
                if len(group_data) < 15:
                    cleaned_data.append(group_data)
                    outlier_info[group_key] = {
                        'original_count': original_count,
                        'removed_count': 0,
                        'final_count': original_count
                    }
                    continue

                # ‡πÉ‡∏ä‡πâ IQR iteratively
                current_data = group_data
                max_iterations = 10
                for _ in range(max_iterations):
                    before_count = len(current_data)
                    Q1 = current_data['uph'].quantile(0.25)
                    Q3 = current_data['uph'].quantile(0.75)
                    IQR = Q3 - Q1
                    filtered_data = current_data[
                        (current_data['uph'] >= Q1 - 1.5*IQR) &
                        (current_data['uph'] <= Q3 + 1.5*IQR)
                    ]
                    after_count = len(filtered_data)
                    if after_count == before_count or after_count < 5 or (before_count - after_count) / before_count > 0.5:
                        break
                    current_data = filtered_data

                cleaned_data.append(current_data)
                final_count = len(current_data)
                outlier_info[group_key] = {
                    'original_count': original_count,
                    'removed_count': original_count - final_count,
                    'final_count': final_count
                }

            result_df = pd.concat(cleaned_data) if cleaned_data else df
            return result_df, outlier_info
        except Exception as e:
            print(f"‚ùå Error in remove_outliers: {e}")
            return df, {}
        
    def match_mat_size_with_optn_code(self, mat_size, optn_code):
        # ‡∏î‡∏∂‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡∏•‡∏ß‡∏î‡∏à‡∏≤‡∏Å optn_code ‡πÄ‡∏ä‡πà‡∏ô "2.0MIL"
        optn_mil = re.search(r'(\d+(\.\d+)?)', optn_code)
        mat_mil = re.search(r'(\d+(\.\d+)?)', mat_size)
        if optn_mil and mat_mil:
            return float(optn_mil.group(1)) == float(mat_mil.group(1))
        return False
    
    def preprocess_data(self, start_date=None, end_date=None):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô"""
        try:
            if self.raw_data is None:
                raise ValueError("No data loaded")
            df = self.raw_data.copy()
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            required_cols = ['uph', 'machine_model', 'bom_no']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise KeyError(f"Missing required columns: {missing_cols}")
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            df['uph'] = pd.to_numeric(df['uph'], errors='coerce')
            df['bom_no'] = df['bom_no'].astype(str).str.strip().str.upper()
            df = df.dropna(subset=['uph', 'bom_no'])
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
            if start_date and end_date:
                print(f"üìÖ Filtering by date: {start_date} - {end_date}")
                date_cols = [col for col in df.columns if 'date' in col or 'time' in col]
                for col in date_cols:
                    try:
                        df[col] = pd.to_datetime(df[col], errors='coerce')
                        start_dt = pd.to_datetime(start_date)
                        end_dt = pd.to_datetime(end_date)
                        df = df[(df[col] >= start_dt) & (df[col] <= end_dt)]
                        print(f"‚úÖ Date filter applied: {len(df)} rows remaining")
                        break
                    except Exception:
                        continue
            df = self.clean_model_names(df)
            self.wb_data = df
            return True
        except Exception as e:
            print(f"‚ùå Error in preprocess_data: {e}")
            return False
    
    def calculate_efficiency(self, start_date=None, end_date=None):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ Map ‡∏ï‡∏≤‡∏° BOM + REV + PKG + PRODUCT NUMBER)"""
        try:
            print(f"üîÑ Starting efficiency calculation...")
            if not self.preprocess_data(start_date=start_date, end_date=end_date):
                print(f"‚ùå Preprocess failed")
                return None
            print(f"üìä Data shape: {self.wb_data.shape}")

            cleaned_data, outlier_info = self.remove_outliers(self.wb_data)
            if cleaned_data.empty:
                print(f"‚ùå No data after outlier removal")
                return None
            print(f"üìä After outlier removal: {cleaned_data.shape}")

            group_keys = ['bom_no', 'machine_model', 'optn_code', 'bom_rev', 'device', 'package_code']
            group_keys = [k for k in group_keys if k in cleaned_data.columns]
            grouped = cleaned_data.groupby(group_keys, dropna=False)

            results = []
            print(f"üìä Processing {len(grouped)} groups...")
            for i, (key_tuple, group) in enumerate(grouped):
                try:
                    if i > 0 and i % 50 == 0:
                        print(f"‚è≥ Progress: {i}/{len(grouped)} groups processed...")

                    if not isinstance(key_tuple, tuple):
                        key_tuple = (key_tuple,)
                    key_dict = dict(zip(group_keys, key_tuple))
                    bom_no       = key_dict.get('bom_no')
                    model        = key_dict.get('machine_model')
                    optn_code    = key_dict.get('optn_code')
                    bom_rev      = key_dict.get('bom_rev')
                    device       = key_dict.get('device')          # = Product Number
                    package_code = key_dict.get('package_code')

                    mean_uph = group['uph'].mean()
                    count_after = len(group)  # ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏±‡∏î outlier

                    operation = group['operation'].iloc[0] if 'operation' in group.columns else 'WB'
                    optn_code_val = optn_code if optn_code is not None else (group['optn_code'].iloc[0] if 'optn_code' in group.columns else 'N/A')

                    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Map: ITEM_NO, NO_BUMP, NUMBER_REQUIRED
                    item_no, no_bump, number_required = self.get_wire_info_for_bom_optn(
                        bom_no,
                        optn_code_val,
                        bom_rev=bom_rev,
                        package_code=package_code,
                        product_number=device  # device = Product Number
                    )

                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì wire_per_unit ‡πÅ‡∏•‡∏∞ UPH (‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô None ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ñ‡πâ‡∏≤ wire2 ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ no_bump/number_required = None)
                    wire_per_unit = None
                    efficiency = None
                    if (no_bump is not None) and (number_required is not None) and (not pd.isna(no_bump)) and (not pd.isna(number_required)):
                        wire_per_unit = self.calculate_wire_per_unit(
                            bom_no,
                            optn_code_val,
                            bom_rev=bom_rev,
                            package_code=package_code,
                            product_number=device
                        )
                        if wire_per_unit is not None and wire_per_unit > 0:
                            efficiency = mean_uph / wire_per_unit

                    outlier_data = outlier_info.get(tuple(key_dict.get(k) for k in group_keys), {
                        'original_count': count_after,
                        'removed_count': 0,
                        'final_count': count_after
                    })
                    original_count = outlier_data.get('original_count', count_after)
                    final_count = outlier_data.get('final_count', count_after)
                    removed_count = outlier_data.get('removed_count', original_count - final_count)

                    result_entry = {
                        'Cust': str(bom_no)[:3],
                        'Package Code': package_code,
                        'Product Number': device,
                        'Bom No': bom_no,
                        'Bom Rev': bom_rev,
                        'Machine Model': model,
                        'Operation': operation,
                        'Optn_Code': optn_code_val,
                        'Item_No': item_no,
                        '#OF BUMP': no_bump,
                        '#OF WIRE': number_required,
                        'Total WireCount': round(wire_per_unit, 2) if wire_per_unit is not None else None,
                        'WPH': round(mean_uph, 2),
                        'UPH': round(efficiency, 3) if efficiency is not None else None,
                        'DataPoints_Before': original_count,
                        'DataPoints_After': final_count,
                        'Outliers_Removed': removed_count
                    }
                    results.append(result_entry)
                except Exception as group_error:
                    print(f"‚ùå Error processing group {key_tuple}: {group_error}")
                    continue

            if not results:
                print(f"‚ùå No results generated")
                return None

            self.efficiency_df = pd.DataFrame(results)

            print(f"‚úÖ Generated {len(self.efficiency_df)} results")
            return self.efficiency_df
        except Exception as e:
            print(f"‚ùå Error in calculate_efficiency: {e}")
            return None
    
    def export_to_excel(self, file_path=None):
        """‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô Excel"""
        try:
            if self.efficiency_df is None or self.efficiency_df.empty:
                print(f"‚ùå No data to export")
                return False
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
            if file_path is None:
                output_dir = 'output_WB_AUTO_UPH'
                os.makedirs(output_dir, exist_ok=True)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_path = os.path.join(output_dir, f'wb_analysis_results_{timestamp}.xlsx')
            else:
                output_directory = os.path.dirname(file_path)
                if output_directory and not os.path.exists(output_directory):
                    os.makedirs(output_directory)
            print(f"üíæ Exporting to: {file_path}")
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel
            with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
                # Sheet 1: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏Å
                print(f"‚úèÔ∏è Writing UPH_Results sheet...")
                self.efficiency_df.to_excel(writer, sheet_name='UPH_Results', index=False)
        
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á
            if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                file_size = os.path.getsize(file_path)
                print(f"‚úÖ Excel file created successfully")
                print(f"‚úÖ File created successfully: {file_path} (size: {file_size} bytes)")
                return True
            else:
                print(f"‚ùå File creation failed")
                return False

        except Exception as e:
            print(f"‚ùå Export error: {e}")
            return False

# === Web Interface Functions ===
def get_available_uph_files():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå UPH ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö"""
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        uph_dir = os.path.join(src_dir, "data_WB")
        
        if not os.path.exists(uph_dir):
            return []
        
        uph_files = []
        for filename in os.listdir(uph_dir):
            if (filename.lower().endswith(('.xlsx', '.xls')) and 
                ('uph' in filename.lower() or 'wb' in filename.lower())):
                uph_files.append({
                    'filename': filename,
                    'filepath': os.path.join(uph_dir, filename),
                    'size': os.path.getsize(os.path.join(uph_dir, filename))
                })
        
        uph_files.sort(key=lambda x: x['filename'])
        return uph_files
        
    except Exception as e:
        print(f"‚ùå Error getting UPH files: {e}")
        return []

def get_wire_data_file():
    """‡∏î‡∏∂‡∏á path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå Wire Data (Part bom pkg.xlsx)"""
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        wire_data_path = os.path.join(src_dir, "data_MAP", "Part bom pkg.xlsx")
        if os.path.exists(wire_data_path):
            return {'filename': os.path.basename(wire_data_path), 'filepath': wire_data_path}
        return None
    except Exception as e:
        print(f"‚ùå Error getting Wire data file: {e}")
        return None

def run_wb_auto_uph_web(selected_uph_file, output_filename=None, start_date=None, end_date=None):
    """‡∏£‡∏±‡∏ô WB_AUTO_UPH ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö"""
    try:
        print(f"üöÄ Starting WB_AUTO_UPH Web Analysis...")
        
        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Wire Data
        wire_data = get_wire_data_file()
        if not wire_data:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data'
            }
        
        # ‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå UPH
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        uph_path = os.path.join(src_dir, "data_WB", selected_uph_file)
        
        if not os.path.exists(uph_path):
            return {
                'success': False,
                'error': f'‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH: {selected_uph_file}'
            }
        
        print(f"üìÅ Files: Wire Data: {wire_data['filename']}, UPH: {selected_uph_file}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á analyzer
        analyzer = WireBondingAnalyzer()
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if not analyzer.load_data(uph_path, wire_data['filepath']):
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ'
            }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        efficiency_df = analyzer.calculate_efficiency(start_date=start_date, end_date=end_date)
        
        if efficiency_df is None or efficiency_df.empty:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ'
            }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output
        if not output_filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"WB_Analysis_{timestamp}.xlsx"
        elif not output_filename.endswith('.xlsx'):
            output_filename += '.xlsx'
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
        temp_dir = os.path.join(src_dir, "temp")
        os.makedirs(temp_dir, exist_ok=True)
        output_path = os.path.join(temp_dir, output_filename)
        
        # Export ‡πÑ‡∏ü‡∏•‡πå
        if not analyzer.export_to_excel(output_path):
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ'
            }
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        total_groups = len(efficiency_df)
        avg_efficiency = efficiency_df['UPH'].mean()
        total_data_points = efficiency_df['Data_Points'].sum()
        total_outliers_removed = efficiency_df['Outliers_Removed'].sum()
        total_original_data = efficiency_df['Original_Count'].sum()
        
        print(f"‚úÖ WB_AUTO_UPH completed successfully!")
        
        return {
            'success': True,
            'message': '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wire Bond ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à',
            'output_file': output_filename,
            'output_path': output_path,
            'summary': {
                'total_groups': total_groups,
                'average_efficiency': round(avg_efficiency, 3),
                'outliers_removed': total_outliers_removed,
                'total_original_data': total_original_data,
                'data_quality': round((1 - total_outliers_removed/total_original_data) * 100, 2) if total_original_data > 0 else 0,
                'total_data_points': total_data_points
            },
            'wire_data_file': wire_data['filename'],
            'uph_data_file': selected_uph_file
        }
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return {
            'success': False,
            'error': f'‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}'
        }

def run(input_dir, output_dir, uph_filename=None, wire_filename=None, **kwargs):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô WB_AUTO_UPH"""
    print(f"üöÄ Starting WB_AUTO_UPH execution...")
    try:
        if not uph_filename:
            raise Exception("‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå UPH")
        # ‡∏£‡∏±‡∏ö start_date, end_date ‡∏à‡∏≤‡∏Å kwargs
        start_date = kwargs.get('start_date', None)
        end_date = kwargs.get('end_date', None)

        analyzer = WireBondingAnalyzer()

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
        uph_file = os.path.join(input_dir, uph_filename)
        # ‡πÉ‡∏ä‡πâ Part bom pkg.xlsx ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        default_wire = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "data_MAP", "Part bom pkg.xlsx")
        wire_file = os.path.join(input_dir, wire_filename) if wire_filename else default_wire
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå
        if not os.path.exists(uph_file):
            raise Exception(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH: {uph_file}")
        if not os.path.exists(wire_file):
            raise Exception(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data: {wire_file}")
        print(f"‚úÖ Files validated")
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if not analyzer.load_data(uph_file, wire_file):
            raise Exception("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        efficiency_df = analyzer.calculate_efficiency(start_date=start_date, end_date=end_date)
        if efficiency_df is None or efficiency_df.empty:
            raise Exception("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, "WB_AUTO_UPH_RESULT.xlsx")
        # Export ‡πÑ‡∏ü‡∏•‡πå
        if not analyzer.export_to_excel(output_path):
            raise Exception("‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
            raise Exception("‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        print(f"‚úÖ WB_AUTO_UPH completed successfully!")
        return output_path
    except Exception as e:
        print(f"‚ùå WB_AUTO_UPH failed: {e}")
        raise e

def WB_AUTO_UPH(input_path, output_dir, start_date=None, end_date=None):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô WB_AUTO_UPH ‡∏´‡∏•‡∏±‡∏Å"""
    try:
        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
        if isinstance(input_path, list):
            result_paths = []
            for f in input_path:
                if os.path.isfile(f):
                    input_dir = os.path.dirname(f)
                    uph_filename = os.path.basename(f)
                    result_path = run(input_dir, output_dir, uph_filename=uph_filename, 
                                    start_date=start_date, end_date=end_date)
                    
                    # ‡πÄ‡∏û‡∏¥‡πà‡∏° mapping
                    #mapped_path = map_data(result_path)
                    result_paths.append(result_path)

            return result_paths[0] if len(result_paths) == 1 else result_paths

        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
        elif isinstance(input_path, str) and os.path.isdir(input_path):
            raise Exception("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")

        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß
        elif os.path.isfile(input_path):
            input_dir = os.path.dirname(input_path)
            uph_filename = os.path.basename(input_path)
            result_path = run(input_dir, output_dir, uph_filename=uph_filename, 
                            start_date=start_date, end_date=end_date)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° mapping
            #mapped_path = map_data(result_path)

            print(f"WB_AUTO_UPH completed. Output: {result_path}")
            return result_path
        else:
            raise Exception("input_path ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    except Exception as e:
        print(f"‚ùå WB_AUTO_UPH workflow failed: {e}")
        raise e